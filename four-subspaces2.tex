\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{titlesec}

\geometry{margin=1in}
\titleformat{\section}{\large\bfseries}{}{0em}{}
\titleformat{\subsection}{\bfseries}{}{0em}{}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\title{The Four Fundamental Subspaces and Their Orthogonality Relations}
\author{}
\date{}

\begin{document}

\maketitle

\Large

In linear algebra, the \textbf{four fundamental subspaces} associated with a real matrix \( A \in \mathbb{R}^{m \times n} \) provide deep insight into the structure of linear systems. These are:
\begin{enumerate}[label=\arabic*.]
    \item Column Space (\( \mathrm{Col}(A) \))
    \item Null Space (\( \mathrm{Nul}(A) \))
    \item Row Space (\( \mathrm{Row}(A) \))
    \item Left Null Space (\( \mathrm{Nul}(A^\top) \))
\end{enumerate}

We will define each subspace and then rigorously prove the key orthogonality relations:
\[
\boxed{\mathrm{Nul}(A) = \mathrm{Row}(A)^\perp} \quad \text{and} \quad \boxed{\mathrm{Nul}(A^\top) = \mathrm{Col}(A)^\perp}
\]

\section*{1. Definitions of the Four Fundamental Subspaces}

Let \( A \) be an \( m \times n \) real matrix.

\subsection*{1.1 Column Space}
The column space of \( A \) is the set of all linear combinations of its columns:
\[
\mathrm{Col}(A) = \left\{ A\mathbf{x} \mid \mathbf{x} \in \mathbb{R}^n \right\} \subseteq \mathbb{R}^m
\]
- Dimension: \( \mathrm{rank}(A) = r \)
- Basis: Pivot columns of \( A \)

\subsection*{1.2 Null Space}
The null space of \( A \) is the set of vectors mapped to zero:
\[
\mathrm{Nul}(A) = \left\{ \mathbf{x} \in \mathbb{R}^n \mid A\mathbf{x} = \mathbf{0} \right\} \subseteq \mathbb{R}^n
\]
- Dimension: \( n - r \) (Rank-Nullity Theorem)
- Basis: Found by solving \( A\mathbf{x} = \mathbf{0} \)

\subsection*{1.3 Row Space}
The row space is the span of the rows of \( A \), or equivalently, the column space of \( A^\top \):
\[
\mathrm{Row}(A) = \mathrm{Col}(A^\top) \subseteq \mathbb{R}^n
\]
- Dimension: \( r \)
- Basis: Nonzero rows in the reduced row echelon form (RREF) of \( A \)

\subsection*{1.4 Left Null Space}
The left null space consists of vectors \( \mathbf{y} \) such that \( A^\top \mathbf{y} = \mathbf{0} \):
\[
\mathrm{Nul}(A^\top) = \left\{ \mathbf{y} \in \mathbb{R}^m \mid A^\top \mathbf{y} = \mathbf{0} \right\} \subseteq \mathbb{R}^m
\]
- Dimension: \( m - r \)
- Basis: Found via elimination on \( A^\top \), or from bottom rows of \( E \) in \( EA = R \)

\section*{2. Orthogonality Relations}

We now prove the two fundamental orthogonal complement relationships.

\subsection*{2.1 \( \mathrm{Nul}(A) = \mathrm{Row}(A)^\perp \)}

We show that a vector \( \mathbf{x} \in \mathbb{R}^n \) satisfies \( A\mathbf{x} = \mathbf{0} \) if and only if \( \mathbf{x} \) is orthogonal to every vector in the row space of \( A \).

Let the rows of \( A \) be \( \mathbf{r}_1, \mathbf{r}_2, \dots, \mathbf{r}_m \in \mathbb{R}^n \). Then:
\[
A\mathbf{x} = 
\begin{bmatrix}
\mathbf{r}_1 \cdot \mathbf{x} \\
\mathbf{r}_2 \cdot \mathbf{x} \\
\vdots \\
\mathbf{r}_m \cdot \mathbf{x}
\end{bmatrix}
\]

Thus,
\[
A\mathbf{x} = \mathbf{0} \iff \mathbf{r}_i \cdot \mathbf{x} = 0 \quad \text{for all } i = 1, \dots, m
\]

Any vector \( \mathbf{v} \in \mathrm{Row}(A) \) is a linear combination:
\[
\mathbf{v} = c_1 \mathbf{r}_1 + \cdots + c_m \mathbf{r}_m
\]

Then:
\[
\mathbf{v} \cdot \mathbf{x} = \sum_{i=1}^m c_i (\mathbf{r}_i \cdot \mathbf{x}) = 0
\]

So \( \mathbf{x} \perp \mathbf{v} \), hence \( \mathbf{x} \in \mathrm{Row}(A)^\perp \).

Conversely, if \( \mathbf{x} \in \mathrm{Row}(A)^\perp \), then in particular \( \mathbf{x} \perp \mathbf{r}_i \) for each row \( \mathbf{r}_i \), so \( A\mathbf{x} = \mathbf{0} \), meaning \( \mathbf{x} \in \mathrm{Nul}(A) \).

Therefore:
\[
\boxed{\mathrm{Nul}(A) = \mathrm{Row}(A)^\perp}
\]

\subsection*{2.2 \( \mathrm{Nul}(A^\top) = \mathrm{Col}(A)^\perp \)}

Now let \( \mathbf{y} \in \mathbb{R}^m \). Consider \( A^\top \mathbf{y} \). The \( j \)-th entry of \( A^\top \mathbf{y} \) is:
\[
(A^\top \mathbf{y})_j = \text{(column } j \text{ of } A) \cdot \mathbf{y} = \mathbf{a}_j \cdot \mathbf{y}
\]

So:
\[
A^\top \mathbf{y} = \mathbf{0} \iff \mathbf{a}_j \cdot \mathbf{y} = 0 \quad \text{for all } j = 1, \dots, n
\]

That is, \( \mathbf{y} \) is orthogonal to every column of \( A \).

Any vector \( \mathbf{w} \in \mathrm{Col}(A) \) is of the form:
\[
\mathbf{w} = d_1 \mathbf{a}_1 + \cdots + d_n \mathbf{a}_n
\]

Then:
\[
\mathbf{y} \cdot \mathbf{w} = \sum_{j=1}^n d_j (\mathbf{y} \cdot \mathbf{a}_j) = 0
\]

So \( \mathbf{y} \perp \mathbf{w} \), hence \( \mathbf{y} \in \mathrm{Col}(A)^\perp \).

Conversely, if \( \mathbf{y} \in \mathrm{Col}(A)^\perp \), then \( \mathbf{y} \cdot \mathbf{a}_j = 0 \) for all \( j \), so \( A^\top \mathbf{y} = \mathbf{0} \), so \( \mathbf{y} \in \mathrm{Nul}(A^\top) \).

Thus:
\[
\boxed{\mathrm{Nul}(A^\top) = \mathrm{Col}(A)^\perp}
\]

\section*{3. Summary}

The four fundamental subspaces satisfy the following orthogonal decompositions:
\[
\mathbb{R}^n = \mathrm{Row}(A) \oplus \mathrm{Nul}(A), \qquad
\mathbb{R}^m = \mathrm{Col}(A) \oplus \mathrm{Nul}(A^\top)
\]
where \( \oplus \) denotes an orthogonal direct sum.

These results are central to the \textbf{Fundamental Theorem of Linear Algebra}, illustrating how a matrix partitions the domain and codomain into mutually orthogonal invariant subspaces.

\end{document}
